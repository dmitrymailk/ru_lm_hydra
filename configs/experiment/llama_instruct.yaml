# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: instruct.yaml
  - override /model: instruct.yaml
  - override /callbacks: default.yaml
  - override /trainer: fsdp.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["ru_instruct", "llama-7b"]

seed: 12345

accumulate_grad_batches: 4
max_epochs: 2

trainer:
  max_epochs: ${max_epochs}
  val_check_interval: 20
  accumulate_grad_batches: ${accumulate_grad_batches}


model:
  max_epochs: ${max_epochs}
  accumulate_grad_batches: ${accumulate_grad_batches}

data:
  train_val_split: [0.9, 0.1]
  train_batch_size: 4
  valid_batch_size: 4
  num_workers: 32
  tokenizer_max_len: 1024


logger:
  wandb:
    tags: ${tags}
    group: "ru_instruct"
  aim:
    experiment: "ru_instruct"
