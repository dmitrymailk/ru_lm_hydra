{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 33/33 [00:10<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "base_model = \"decapoda-research/llama-7b-hf\"\n",
    "device_map = \"auto\"\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    # load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\n",
    "tokenizer.padding_side = \"left\"  # Allow batched inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(prompt):\n",
    "    # print(prompt)\n",
    "    prompt = prompt[\"prompt\"]\n",
    "\n",
    "    tokenized_prompt = tokenizer(\n",
    "        prompt,\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "    )\n",
    "    user_prompt = prompt[: prompt.index(\"### Assistant:\")]\n",
    "    tokenized_user_prompt = tokenizer(\n",
    "        user_prompt,\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "    tokenized_prompt[\"labels\"] = [-100] * (prompt_len) + tokenized_prompt[\"input_ids\"][\n",
    "        prompt_len:\n",
    "    ]\n",
    "    return tokenized_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/kosenko/.cache/huggingface/datasets/json/default-8fca4c8833304c51/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.74it/s]\n",
      "                                                                                  \r"
     ]
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"/home/kosenko/ru_chatGPT/ru_instruct/ru_instruct/sandbox/datasets_processed/IlyaGusev_ru_turbo_alpaca_formatted.json\"\n",
    "}\n",
    "data = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=data_files,\n",
    ")\n",
    "\n",
    "# всеравно мы никак не можем адекватно мерить модель\n",
    "# тогда зачем тратить на валидацию данные?\n",
    "train_data = (\n",
    "    data[\"train\"]\n",
    "    .shuffle()\n",
    "    .map(\n",
    "        generate_and_tokenize_prompt,\n",
    "        num_proc=32,\n",
    "        # batched=True,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
      "\n",
      "### Human: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Как вы относитесь к конкуренции на рабочем месте?\n",
      "\n",
      "### Response:\n",
      "### Assistant:\n",
      "Я считаю, что конкуренция на рабочем месте может быть полезной, если она справедливая и здоровая. Конкуренция может стимулировать улучшение работы и повышение производительности. Однако, я также считаю, что важно сохранять здоровую рабочую среду и отношения с коллегами. Я всегда стараюсь помогать своим коллегам и делиться своими знаниями и опытом, чтобы мы могли достигать успеха вместе.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[\"train\"][1000][\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 75368\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
      "\n",
      "### Human: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Напиши краткое объяснение сложной теории или концепции.\n",
      "Клеточные автоматы.\n",
      "### Response:\n",
      "### Assistant:\n",
      "Клеточный автомат - это математическая модель, представляющая собой сетку клеток, которые могут находиться в одном из конечного числа состояний. Каждая клетка взаимодействует со своими соседями в зависимости от определенных правил, которые могут зависеть от текущего состояния клетки и ее соседей. Такие модели используются для исследования различных явлений, включая распространение эпидемии и физических процессов в материалах, а также для создания сложных компьютерных моделей искусственного интеллекта.\n",
      "\n",
      "\n",
      "<unk>\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
      "\n",
      "### Human: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Напиши краткое объяснение сложной теории или концепции.\n",
      "Клеточные автоматы.\n",
      "### Response:\n",
      "### Assistant:\n",
      "Клеточный автомат - это математическая модель, представляющая собой сетку клеток, которые могут находиться в одном из конечного числа состояний. Каждая клетка взаимодействует со своими соседями в зависимости от определенных правил, которые могут зависеть от текущего состояния клетки и ее соседей. Такие модели используются для исследования различных явлений, включая распространение эпидемии и физических процессов в материалах, а также для создания сложных компьютерных моделей искусственного интеллекта.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][\"prompt\"])\n",
    "print(tokenizer.decode(train_data[0][\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.remove_columns(\"prompt\")\n",
    "splited_dataset = train_data.train_test_split(train_size=0.98, test_size=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 73860\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1508\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splited_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = transformers.DataCollatorForSeq2Seq(\n",
    "\ttokenizer=tokenizer,\n",
    "\tpad_to_multiple_of=8,\n",
    " \treturn_tensors=\"pt\", \n",
    "  \tpadding=True\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "\tdataset=splited_dataset['train'],\n",
    "\tbatch_size=1,\n",
    "\t# num_workers=self.hparams.num_workers,\n",
    "\tpin_memory=True,\n",
    "\tshuffle=True,\n",
    " \tcollate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,     0,     0, 29871,    13,    13, 29909, 13563,  1546,   263,\n",
       "         12758,  5199,   322,   385, 23116, 21082, 20255, 29889,   450, 20255,\n",
       "          4076,  8444, 29892, 13173, 29892,   322,  1248,   568,  6089,   304,\n",
       "           278,  5199, 29915, 29879,  5155, 29889,    13,    13,  2277, 29937,\n",
       "         12968, 29901, 13866,   338,   385, 15278,   393, 16612,   263,  3414,\n",
       "         29889, 14350,   263,  2933,   393,  7128,  2486,  1614,  2167,   278,\n",
       "          2009, 29889,    13,    13,  2277, 29937,  2799,  4080, 29901,    13,\n",
       "         19193,  1668,  1911, 20658,  6195, 10539, 12189,   376,   587, 14370,\n",
       "          6988,  2031,  2370, 21424,   644, 29972,  1642,    13,    13,  2277,\n",
       "         29937, 13291, 29901,    13,  2277, 29937,  4007, 22137, 29901,    13,\n",
       "         30027, 29919, 14370,  6988,  2031,  2370, 21424,   644, 29972,   448,\n",
       "          6408,  2591, 19851, 14760, 20148, 29957, 20565,  1587, 29892, 12423,\n",
       "          8838, 29982, 25107,   665,  2771, 15432, 24846, 26874, 11012, 14700,\n",
       "          5010,   606, 13388,  2942,  2387,  8535, 29889, 16456, 24160,  4364,\n",
       "          3807, 20658,  6052,  3485,  5985,   606, 21946,  2510,  5395, 26874,\n",
       "         11012,  1077, 22472, 16574,  2942,  2387,  2082,   606, 25816,  7082,\n",
       "         15587,   693, 21456, 18972, 22472,  5588,   989,  2942,  2387,  8535,\n",
       "         29889, 22443, 11332,  4816,  1909, 14370,  6988,  2031,  1868, 21424,\n",
       "         19129, 14367,   863,  3766, 16990, 29892,  6999, 18805, 26149, 23401,\n",
       "          4570,  2494, 10706,  1413,  6253, 12395,  1077, 22472, 16574,  2942,\n",
       "          2387,  2082,   665,  8838, 29919, 14292,  2430,  6253,  1093,  2332,\n",
       "         18972, 22472,  5588, 29988,  2942,  2387,  2430, 29889,  7222, 14370,\n",
       "          6988,  2031,  2370, 21424,   644, 29972, 24069,   551, 24160,  4364,\n",
       "           490, 24297,   989,  2476, 29892,  5660, 22651,  1502, 29892,  7956,\n",
       "          2476,   606, 11935,  5055,   464, 13053, 29892, 11270, 23842,  4647,\n",
       "          1630,   614,  2421,   507, 24058,   490,  1902, 29917,  1630, 29935,\n",
       "          5543,  8904, 11012, 16481, 29981,  8535,  2942,  2387,  8535, 29889,\n",
       "            13,    13]]), 'attention_mask': tensor([[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,    13,  2277, 29937,  4007, 22137, 29901,    13,\n",
       "         30027, 29919, 14370,  6988,  2031,  2370, 21424,   644, 29972,   448,\n",
       "          6408,  2591, 19851, 14760, 20148, 29957, 20565,  1587, 29892, 12423,\n",
       "          8838, 29982, 25107,   665,  2771, 15432, 24846, 26874, 11012, 14700,\n",
       "          5010,   606, 13388,  2942,  2387,  8535, 29889, 16456, 24160,  4364,\n",
       "          3807, 20658,  6052,  3485,  5985,   606, 21946,  2510,  5395, 26874,\n",
       "         11012,  1077, 22472, 16574,  2942,  2387,  2082,   606, 25816,  7082,\n",
       "         15587,   693, 21456, 18972, 22472,  5588,   989,  2942,  2387,  8535,\n",
       "         29889, 22443, 11332,  4816,  1909, 14370,  6988,  2031,  1868, 21424,\n",
       "         19129, 14367,   863,  3766, 16990, 29892,  6999, 18805, 26149, 23401,\n",
       "          4570,  2494, 10706,  1413,  6253, 12395,  1077, 22472, 16574,  2942,\n",
       "          2387,  2082,   665,  8838, 29919, 14292,  2430,  6253,  1093,  2332,\n",
       "         18972, 22472,  5588, 29988,  2942,  2387,  2430, 29889,  7222, 14370,\n",
       "          6988,  2031,  2370, 21424,   644, 29972, 24069,   551, 24160,  4364,\n",
       "           490, 24297,   989,  2476, 29892,  5660, 22651,  1502, 29892,  7956,\n",
       "          2476,   606, 11935,  5055,   464, 13053, 29892, 11270, 23842,  4647,\n",
       "          1630,   614,  2421,   507, 24058,   490,  1902, 29917,  1630, 29935,\n",
       "          5543,  8904, 11012, 16481, 29981,  8535,  2942,  2387,  8535, 29889,\n",
       "            13,    13]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = next(iter(dataloader))\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8252, dtype=torch.float16, grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/kosenko/ru_chatGPT/ru_instruct/ru_instruct/sandbox/datasets_processed/IlyaGusev_ru_turbo_alpaca_formatted.json']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(['/home/kosenko/ru_chatGPT/ru_instruct/ru_instruct/sandbox/datasets_processed/IlyaGusev_ru_turbo_alpaca_formatted.json'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
